# üîê Trust Engine Application - Comprehensive Guide

## üìã Table of Contents
1. [System Architecture](#-system-architecture)
2. [Prerequisites & Setup](#Ô∏è-prerequisites--setup)
3. [Running the Application](#-running-the-application)
4. [How the Application Works](#Ô∏è-how-the-application-works)
5. [User Perspectives](#-user-perspectives)
6. [API Documentation](#-api-documentation)
7. [Monitoring & Visualization](#-monitoring--visualization)
8. [Troubleshooting](#-troubleshooting)
9. [Production Deployment](#-production-deployment-checklist)

---

## üèóÔ∏è System Architecture

### High-Level Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Remote Users   ‚îÇ    ‚îÇ   VM Agents     ‚îÇ    ‚îÇ  Administrators ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ                      ‚îÇ
          ‚ñº                      ‚ñº                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Trust Engine API                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ   Auth API  ‚îÇ ‚îÇ   ML API    ‚îÇ ‚îÇ Wazuh API   ‚îÇ ‚îÇ Telemetry   ‚îÇ‚îÇ
‚îÇ  ‚îÇ   (Okta)    ‚îÇ ‚îÇ(6 Models)   ‚îÇ ‚îÇ Integration ‚îÇ ‚îÇ   API       ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ                      ‚îÇ
          ‚ñº                      ‚ñº                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Supabase      ‚îÇ    ‚îÇ  Elasticsearch  ‚îÇ    ‚îÇ  Wazuh Stack    ‚îÇ
‚îÇ   (Database)    ‚îÇ    ‚îÇ   (Storage)     ‚îÇ    ‚îÇ   (Security)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ     Kibana      ‚îÇ
                      ‚îÇ (Visualization) ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Details
- Trust Engine: Main Flask application (Port 5001)
- Elasticsearch: Data storage and search (Port 9200)
- Kibana: Data visualization and dashboards (Port 5601)
- Wazuh Manager: Security monitoring (Ports 1514, 1515, 55000)
- Wazuh Indexer: OpenSearch backend (Port 9201)
- Wazuh Dashboard: Security dashboards (Port 5602)

### Technology Stack
- Backend: Python Flask, scikit-learn, pandas, numpy
- ML Models: 6 classifiers (RandomForest, KNN, NaiveBayes, MLP, AdaptiveKNN, AdaptiveRandomForest)
- Database: Supabase (PostgreSQL), Elasticsearch
- Authentication: Okta SSO
- Security: Wazuh SIEM
- Visualization: Kibana, Matplotlib, Seaborn
- Containerization: Docker, Docker Compose

---

## üõ†Ô∏è Prerequisites & Setup

### System Requirements
```bash
# Hardware Requirements
- CPU: 4+ cores recommended
- RAM: 8GB minimum, 16GB recommended
- Disk: 20GB free space
- Network: Internet access for external services

# Software Requirements
- Docker & Docker Compose
- Python 3.9+ (if running locally)
- curl/wget for testing
```

### Environment Setup

1. Clone and Setup Project
```bash
# Navigate to project directory
cd trust_engine_app

# Copy environment template (if exists)
cp .env.example .env

# Edit configuration
nano .env
```

2. Required Environment Variables
```bash
# Supabase Configuration
SUPABASE_URL=your_supabase_project_url
SUPABASE_API_KEY=your_supabase_anon_key

# Okta Authentication
OKTA_ISSUER=https://your-domain.okta.com
OKTA_CLIENT_ID=your_okta_client_id
OKTA_CLIENT_SECRET=your_okta_client_secret
OKTA_REDIRECT_URI=https://localhost:5001/authorization-code/callback
OKTA_AUDIENCE=api://default

# Flask Configuration
FLASK_SECRET_KEY=your_secure_secret_key
FLASK_ENV=development
FLASK_DEBUG=1

# Elasticsearch Configuration
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_USERNAME=elastic
ELASTICSEARCH_PASSWORD=trust-engine-elastic-password

# Wazuh Configuration
WAZUH_API_URL=https://localhost:55000
WAZUH_API_USERNAME=wazuh-wui
WAZUH_API_PASSWORD=MyS3cr37P450r.*-
```

3. SSL Certificate Setup (Optional)
```bash
# Generate SSL certificates for HTTPS
cd docker/ssl
./generate_certificates.sh

# Or create self-signed certificates
openssl req -x509 -newkey rsa:4096 -keyout private/trust-engine-key.pem \
  -out certs/trust-engine-cert.pem -days 365 -nodes
```

---

## üöÄ Running the Application

### Method 1: Docker Compose (Recommended)

Step 1: Start the Full Stack
```bash
cd trust_engine_app

# Start all services
docker-compose up -d

# Check service status
docker-compose ps
```

Expected Output:
```
         Name                     Command               State                    Ports
-------------------------------------------------------------------------------------------------
trust-elasticsearch    /bin/tini -- /usr/local/bi ...   Up      0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp
trust-engine-app       python run.py                    Up      0.0.0.0:5001->5001/tcp
trust-kibana           /bin/tini -- /usr/local/bi ...   Up      0.0.0.0:5601->5601/tcp
wazuh.dashboard-1      /entrypoint.sh opensearch ...   Up      0.0.0.0:443->5601/tcp
wazuh.indexer-1        /entrypoint.sh opensearch ...   Up      0.0.0.0:9202->9200/tcp
wazuh.manager-1        /init                            Up      0.0.0.0:1514->1514/tcp, 
                                                                0.0.0.0:514->514/udp, 
                                                                0.0.0.0:1515->1515/tcp, 
                                                                0.0.0.0:55000->55000/tcp
```

Step 2: Verify Services
```bash
# Test Trust Engine API
curl http://localhost:5001/

# Test Elasticsearch
curl http://localhost:9200/_cluster/health

# Test ML API
curl http://localhost:5001/api/ml/health

# Expected ML API Response:
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00.000000",
  "ml_engine": "initialized",
  "classifiers_available": [
    "RandomForest", "KNN", "NaiveBayes", 
    "MLP", "AdaptiveKNN", "AdaptiveRandomForest"
  ],
  "models_trained": false,
  "version": "1.0.0"
}
```

Step 3: Access Web Interfaces
```bash
# Trust Engine API
http://localhost:5001/

# Kibana Dashboard
http://localhost:5601/
# Credentials: elastic / trust-engine-elastic-password

# Wazuh Dashboard
https://localhost:5602/
# Credentials: admin / SecretPassword
```

### Method 2: Local Development

Step 1: Setup Python Environment
```bash
cd trust_engine_app

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

Step 2: Start External Services
```bash
# Start only infrastructure services
docker-compose up -d elasticsearch kibana wazuh-manager wazuh-indexer wazuh-dashboard
```

Step 3: Run Trust Engine Locally
```bash
# Run the application
python run.py

# Or with specific settings
FLASK_ENV=development FLASK_DEBUG=1 python run.py
```

### Service Startup Order
1. Elasticsearch (Wait 2-3 minutes for full startup)
2. Wazuh Indexer (Wait 1-2 minutes)
3. Kibana (Depends on Elasticsearch)
4. Wazuh Manager & Dashboard (Depends on Indexer)
5. Trust Engine App (Can start independently)

---

## ‚öôÔ∏è How the Application Works

### 1. Authentication Flow

```
User Request ‚Üí Okta Login ‚Üí ML Trust Evaluation ‚Üí Access Decision
     ‚Üì              ‚Üì               ‚Üì                    ‚Üì
Access URL ‚Üí Redirect Login ‚Üí Analyze Features ‚Üí Grant/Deny/MFA
```

Detailed Flow:
1. User attempts to access protected resource
2. System redirects to Okta for authentication
3. User provides credentials to Okta
4. Okta returns authorization code to Trust Engine
5. Trust Engine exchanges code for access tokens
6. ML engine analyzes user/session features
7. Trust score calculated (1-10 scale)
8. Access decision made based on score
9. User granted access, denied, or required MFA

### 2. Trust Score Calculation

Data Collection:
```python
# Network flow features (69 CICIDS2017 features)
features = {
    'Flow Duration': 0.123,
    'Total Fwd Packets': 45,
    'Total Backward Packets': 23,
    'Total Length of Fwd Packets': 1234,
    'Total Length of Bwd Packets': 567,
    'Fwd Packet Length Max': 89,
    'Fwd Packet Length Min': 12,
    # ... 62 more features
    'Init_Win_bytes_forward': 65535,
    'Init_Win_bytes_backward': 65535,
    'act_data_pkt_fwd': 0,
    'min_seg_size_forward': 20
}
```

ML Processing:
```python
# 6 ML Classifiers process features simultaneously
classifiers = {
    'RandomForest': 'Ensemble method for robust predictions',
    'KNN': 'Instance-based learning',
    'NaiveBayes': 'Probabilistic classifier',
    'MLP': 'Multi-layer perceptron neural network',
    'AdaptiveKNN': 'Adaptive instance-based learning',
    'AdaptiveRandomForest': 'Adaptive ensemble method'
}

# Each classifier returns trust score 1-10
individual_scores = [8.5, 7.2, 9.1, 8.8, 7.9, 8.3]
final_score = weighted_average(individual_scores)
```

Trust Score Mapping:
```python
def determine_access_decision(trust_score):
    if trust_score >= 8:
        return {
            "risk_level": "LOW_RISK",
            "access": "ALLOW",
            "mfa_required": False,
            "message": "Access granted - low security risk"
        }
    elif trust_score >= 5:
        return {
            "risk_level": "MEDIUM_RISK", 
            "access": "ALLOW",
            "mfa_required": True,
            "message": "Access granted - MFA required"
        }
    elif trust_score >= 3:
        return {
            "risk_level": "HIGH_RISK",
            "access": "CONDITIONAL",
            "mfa_required": True,
            "message": "Limited access - enhanced monitoring"
        }
    else:
        return {
            "risk_level": "CRITICAL_RISK",
            "access": "DENY", 
            "mfa_required": False,
            "message": "Access denied - critical security risk"
        }
```

### 3. Data Pipeline Architecture

```
VM Agents ‚Üí Telemetry ‚Üí Feature Extraction ‚Üí ML Processing ‚Üí Trust Score ‚Üí Access Control
    ‚Üì           ‚Üì              ‚Üì                  ‚Üì             ‚Üì              ‚Üì
[Network    [JSON         [69 CICIDS2017     [6 Parallel    [Weighted      [Allow/Deny/
 Traffic]    Data]         Features]          Classifiers]   Average]       MFA Required]
    ‚Üì           ‚Üì              ‚Üì                  ‚Üì             ‚Üì              ‚Üì
Elasticsearch ‚Üí Preprocessing ‚Üí Normalization ‚Üí Prediction ‚Üí Evaluation ‚Üí Response API
```

### 4. ML Model Training Process

Training Pipeline Steps:
1. Data Loading: Load CICIDS2017 dataset from JSON files
2. Feature Engineering: Extract and normalize 69 network features
3. Data Splitting: 80% training, 20% testing
4. Model Training: Train 6 different classifiers in parallel
5. Cross-Validation: 5-fold CV for model validation
6. Performance Evaluation: Calculate accuracy, precision, recall, F1
7. Model Storage: Save trained models for inference

Training Configuration:
```json
{
  "use_sample_data": true,
  "data_source": "sample_template",
  "test_size": 0.2,
  "cross_validation": true,
  "cv_folds": 5,
  "save_models": true,
  "model_path": "models/"
}
```

### 5. Real-time Prediction Pipeline

Inference Flow:
```python
# 1. Receive telemetry data
POST /telemetry
{
  "session_id": "session_12345",
  "vm_id": "vm_001", 
  "features": { /* 69 CICIDS2017 features */ }
}

# 2. Feature preprocessing
normalized_features = preprocess_features(raw_features)

# 3. Parallel prediction from 6 models
predictions = []
for model_name, model in trained_models.items():
    score = model.predict(normalized_features)
    confidence = model.predict_proba(normalized_features).max()
    predictions.append({
        "model": model_name,
        "trust_score": score,
        "confidence": confidence
    })

# 4. Weighted ensemble prediction
final_trust_score = calculate_weighted_average(predictions)

# 5. Access decision
decision = determine_access_decision(final_trust_score)

# 6. Response
{
  "trust_score": 8.5,
  "access_decision": "ALLOW",
  "mfa_required": false,
  "confidence": 0.92,
  "processing_time_ms": 18.5,
  "model_contributions": predictions
}
```

---

## üë• User Perspectives

### 1. End User (Remote Worker)

Daily Workflow:
```bash
# Morning login
1. User opens company application: https://company.com/app
2. Redirected to Okta: https://company.okta.com/login
3. Enters credentials (username/password)
4. Trust Engine evaluates session in background
5. High trust score (8.5/10) ‚Üí Direct access granted
6. User accesses application normally

# Afternoon session (different network)
1. User accesses same application from coffee shop
2. Already authenticated, but new network detected
3. Trust Engine re-evaluates: Medium trust (6.2/10)
4. System prompts: "Please verify with MFA for security"
5. User completes MFA ‚Üí Access granted with monitoring

# Evening access (suspicious activity detected)
1. User tries to access sensitive data
2. Trust Engine detects unusual pattern: Low trust (2.8/10)
3. System response: "Access denied - please contact IT"
4. Security team notified automatically
```

User Experience Examples:

Scenario A: High Trust (Score 8-10)
```json
{
  "access": "granted",
  "trust_score": 8.5,
  "risk_level": "LOW",
  "mfa_required": false,
  "message": "Welcome! Access granted.",
  "additional_verification": false
}
```

Scenario B: Medium Trust (Score 5-7)
```json
{
  "access": "conditional", 
  "trust_score": 6.2,
  "risk_level": "MEDIUM",
  "mfa_required": true,
  "message": "Please complete additional verification",
  "mfa_methods": ["SMS", "Authenticator", "Email"]
}
```

Scenario C: Low Trust (Score 1-4)
```json
{
  "access": "denied",
  "trust_score": 2.8,
  "risk_level": "HIGH", 
  "mfa_required": false,
  "message": "Access denied due to security concerns. Please contact your administrator.",
  "contact_info": "security@company.com"
}
```

### 2. VM Agent (Automated System)

Agent Configuration:
```python
# VM Agent Setup
from trust_engine_agent import TrustEngineAgent

agent = TrustEngineAgent(
    endpoint="http://localhost:5001",
    vm_id="vm_001",
    api_key="vm_agent_api_key"
)

# Continuous monitoring
while True:
    # Collect network flow data
    flow_data = collect_network_flows()
    
    # Send telemetry
    response = agent.send_telemetry(flow_data)
    
    # Process response
    if response['trust_score'] < 5:
        agent.trigger_security_alert(response)
    
    time.sleep(60)  # Monitor every minute
```

Telemetry Submission:
```bash
# VM agent sends network flow data
curl -X POST http://localhost:5001/telemetry \
  -H "Authorization: Bearer vm_agent_token" \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "session_12345",
    "vm_id": "vm_001",
    "event_type": "network_flow", 
    "timestamp": "2024-01-15T10:30:00Z",
    "Flow Duration": 0.123,
    "Total Fwd Packets": 45,
    "Total Backward Packets": 23,
    "Total Length of Fwd Packets": 1234,
    "Fwd Packet Length Max": 89,
    "Flow Bytes/s": 1000000,
    "Init_Win_bytes_forward": 65535
  }'
```

Agent Response Handling:
```json
{
  "status": "processed",
  "trust_score": 7.8,
  "risk_level": "MEDIUM",
  "stride_category": "Information Disclosure", 
  "recommendations": [
    "Continue monitoring network traffic",
    "Enable enhanced logging",
    "Review user access patterns"
  ],
  "actions_required": false,
  "timestamp": "2024-01-15T10:30:01Z"
}
```

### 3. Security Administrator

Daily Operations Dashboard:
```bash
# Morning security briefing
1. Check overnight alerts: curl http://localhost:5001/api/ml/alerts
2. Review trust score trends: Access Kibana dashboard
3. Analyze model performance: curl http://localhost:5001/api/ml/models
4. Update threat intelligence: Update Wazuh rules

# Model management tasks
1. Retrain models weekly: POST /api/ml/train
2. Evaluate model drift: POST /api/ml/evaluate  
3. Update feature weights: PUT /api/ml/models/weights
4. Generate compliance reports: GET /api/ml/reports/compliance
```

Administrative Interface:
```bash
# Security Dashboard URLs
http://localhost:5601/app/dashboards          # Kibana ML dashboards
https://localhost:5602/                       # Wazuh security dashboard  
http://localhost:5001/admin/                  # Trust Engine admin panel

# Key administrative APIs
GET  /api/ml/health                          # System health check
GET  /api/ml/models                          # Model status and performance
POST /api/ml/train                           # Retrain ML models
POST /api/ml/evaluate                        # Generate evaluation report
GET  /api/ml/visualize/performance_comparison # Performance charts
POST /api/ml/benchmark                       # System performance test
```

Alert Management:
```python
# Python script for alert handling
import requests
import json

def check_security_alerts():
    # Get current alerts
    response = requests.get('http://localhost:5001/api/alerts')
    alerts = response.json()
    
    high_risk_sessions = [
        alert for alert in alerts 
        if alert['trust_score'] < 3
    ]
    
    if high_risk_sessions:
        # Send notification to security team
        send_security_notification(high_risk_sessions)
        
        # Auto-block if necessary
        for session in high_risk_sessions:
            if session['trust_score'] < 2:
                block_session(session['session_id'])

def generate_daily_report():
    # Generate comprehensive security report
    report_data = {
        'total_sessions': get_session_count(),
        'avg_trust_score': get_average_trust_score(),
        'high_risk_count': get_high_risk_count(),
        'model_performance': get_model_metrics()
    }
    
    save_report(report_data)
    email_report_to_team(report_data)
```

### 4. Data Scientist/Researcher

Research and Development Workflow:
```python
# Advanced ML experimentation
from trust_engine_sdk import TrustEngineClient, ModelExperiment

# Initialize client
client = TrustEngineClient("http://localhost:5001", 
                          api_key="research_api_key")

# Experiment 1: Feature importance analysis
experiment = ModelExperiment(client)
feature_importance = experiment.analyze_feature_importance(
    models=['RandomForest', 'AdaptiveRandomForest'],
    method='permutation'
)

# Experiment 2: Model comparison
comparison = experiment.compare_models(
    models=['RandomForest', 'MLP', 'AdaptiveKNN'],
    metrics=['accuracy', 'precision', 'recall', 'f1', 'auc'],
    cross_validation=True,
    cv_folds=10
)

# Experiment 3: Hyperparameter optimization
best_params = experiment.optimize_hyperparameters(
    model='RandomForest',
    param_grid={
        'n_estimators': [50, 100, 200],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10]
    },
    scoring='f1_weighted'
)

# Experiment 4: Real-time model monitoring
monitor = experiment.setup_model_monitoring(
    models=['RandomForest', 'MLP'],
    metrics=['accuracy', 'drift_score'],
    alert_threshold=0.05
)
```

Custom Model Development:
```python
# Custom classifier implementation
class CustomTrustClassifier:
    def __init__(self):
        self.base_models = []
        self.meta_model = None
        
    def fit(self, X, y):
        # Train base models
        for model in self.base_models:
            model.fit(X, y)
            
        # Train meta-model on base predictions
        base_predictions = self._get_base_predictions(X)
        self.meta_model.fit(base_predictions, y)
        
    def predict(self, X):
        base_predictions = self._get_base_predictions(X)
        return self.meta_model.predict(base_predictions)
        
    def predict_proba(self, X):
        base_predictions = self._get_base_predictions(X)
        return self.meta_model.predict_proba(base_predictions)

# Register custom model with Trust Engine
client.register_custom_model('CustomTrust', CustomTrustClassifier())

# Train and evaluate
results = client.train_models(
    models=['RandomForest', 'CustomTrust'],
    data_source='research_dataset',
    evaluation_metrics=['accuracy', 'f1', 'auc', 'trust_calibration']
)
```

Research Data Analysis:
```python
# Comprehensive data analysis
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load research dataset
df = client.get_training_data(include_predictions=True)

# Analyze trust score distribution
plt.figure(figsize=(12, 8))
plt.subplot(2, 2, 1)
df['trust_score'].hist(bins=50, alpha=0.7)
plt.title('Trust Score Distribution')
plt.xlabel('Trust Score')
plt.ylabel('Frequency')

# Feature correlation analysis
plt.subplot(2, 2, 2)
corr_matrix = df.select_dtypes(include=[np.number]).corr()
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')
plt.title('Feature Correlation Matrix')

# Model performance comparison
plt.subplot(2, 2, 3)
model_performance = client.get_model_performance()
models = list(model_performance.keys())
accuracies = [model_performance[m]['accuracy'] for m in models]
plt.bar(models, accuracies)
plt.title('Model Accuracy Comparison')
plt.xticks(rotation=45)

# Prediction confidence analysis
plt.subplot(2, 2, 4)
df['confidence'].hist(bins=30, alpha=0.7)
plt.title('Prediction Confidence Distribution')
plt.xlabel('Confidence Score')
plt.ylabel('Frequency')

plt.tight_layout()
plt.savefig('research_analysis.png', dpi=300, bbox_inches='tight')
```

---

## üìö API Documentation

### Core API Endpoints

#### Authentication Endpoints
```bash
# Okta SSO Integration
GET  /auth/login                    # Initiate Okta SSO login
GET  /auth/logout                   # User logout  
GET  /auth/user                     # Get current user information
GET  /auth/callback                 # Okta callback handler
POST /auth/vm-agent/login           # VM agent authentication
```

#### ML API Endpoints
```bash
# Core ML Operations
GET  /api/ml/health                 # ML system health check
GET  /api/ml/status                 # Detailed ML system status
GET  /api/ml/models                 # List all trained models
POST /api/ml/train                  # Train ML models
POST /api/ml/predict                # Single prediction
POST /api/ml/predict/batch          # Batch predictions
POST /api/ml/evaluate               # Model evaluation
DELETE /api/ml/models              # Clear all models

# Visualization and Analytics
GET  /api/ml/visualize/<chart_type>     # Generate visualizations
POST /api/ml/benchmark                  # Performance benchmarking
GET  /api/ml/reports/<report_type>      # Generate reports
```

#### Telemetry and Data Endpoints
```bash
# Data Ingestion
POST /telemetry                         # Ingest telemetry data
GET  /trust_score                       # Get trust score for session
POST /generate_synthetic_telemetry      # Generate test data
POST /test_sample_data                  # Test with sample CICIDS2017 data

# Data Management
GET  /api/data/sessions                 # List all sessions
GET  /api/data/sessions/<session_id>    # Get specific session
DELETE /api/data/sessions/<session_id> # Delete session data
```

#### Wazuh Integration Endpoints
```bash
# Wazuh SIEM Integration
GET  /wazuh/agents                      # List Wazuh agents
GET  /wazuh/alerts                      # Get security alerts  
POST /wazuh/process-alerts              # Process alerts as telemetry
GET  /wazuh/test                        # Test Wazuh connection
GET  /wazuh/simulation/agents           # Get simulated agents (demo)
GET  /wazuh/simulation/alerts           # Get simulated alerts (demo)
POST /wazuh/simulation/process          # Process simulated alerts
```

### API Usage Examples

#### 1. ML Model Training
```bash
# Basic training with sample data
curl -X POST http://localhost:5001/api/ml/train \
  -H "Content-Type: application/json" \
  -d '{
    "use_sample_data": true,
    "data_source": "sample_template",
    "test_size": 0.2,
    "cross_validation": true,
    "cv_folds": 5,
    "save_models": true
  }'

# Training with multiple data files
curl -X POST http://localhost:5001/api/ml/train \
  -H "Content-Type: application/json" \
  -d '{
    "use_sample_data": true,
    "data_source": "multiple_files", 
    "algorithms": ["RandomForest", "MLP", "AdaptiveKNN"],
    "test_size": 0.3,
    "cross_validation": true,
    "hyperparameter_tuning": true
  }'

# Response example
{
  "status": "success",
  "message": "All classifiers trained successfully",
  "training_time_seconds": 487.23,
  "models_trained": [
    "RandomForest", "KNN", "NaiveBayes", 
    "MLP", "AdaptiveKNN", "AdaptiveRandomForest"
  ],
  "performance_summary": {
    "RandomForest": {"accuracy": 0.85, "f1": 0.82},
    "MLP": {"accuracy": 0.78, "f1": 0.75},
    // ... other models
  }
}
```

#### 2. Trust Score Prediction
```bash
# Single prediction
curl -X POST http://localhost:5001/api/ml/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": {
      "Flow Duration": 0.123,
      "Total Fwd Packets": 45,
      "Total Backward Packets": 23,
      "Total Length of Fwd Packets": 1234,
      "Flow Bytes/s": 1000000,
      "Init_Win_bytes_forward": 65535
    },
    "classifier": "RandomForest"
  }'

# Response
{
  "trust_score": 8.5,
  "confidence": 0.92,
  "risk_level": "LOW_RISK",
  "mfa_required": false,
  "access_decision": "ALLOW",
  "authentication_latency_ms": 18.5,
  "model_used": "RandomForest",
  "timestamp": "2024-01-15T10:30:00Z",
  "feature_contributions": {
    "Flow Duration": 0.12,
    "Total Fwd Packets": 0.08,
    // ... other features
  }
}

# Batch predictions
curl -X POST http://localhost:5001/api/ml/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "batch_features": [
      {
        "Flow Duration": 0.123,
        "Total Fwd Packets": 45,
        "Total Backward Packets": 23,
        "Flow Bytes/s": 1000000
      },
      {
        "Flow Duration": 0.456,
        "Total Fwd Packets": 32,
        "Total Backward Packets": 18,
        "Flow Bytes/s": 750000
      }
    ],
    "classifier": "RandomForest"
  }'

# Batch response
{
  "status": "success",
  "predictions": [
    {
      "sample_id": 0,
      "trust_score": 8.5,
      "confidence": 0.92,
      "risk_level": "LOW_RISK"
    },
    {
      "sample_id": 1,
      "trust_score": 6.2,
      "confidence": 0.87,
      "risk_level": "MEDIUM_RISK"
    }
  ],
  "processing_time_ms": 45.3,
  "total_samples": 2
}
```

#### 3. Model Management
```bash
# Get all trained models
curl http://localhost:5001/api/ml/models | jq .

# Response
{
  "status": "success",
  "model_info": {
    "trained_models": [
      "RandomForest", "KNN", "NaiveBayes", 
      "MLP", "AdaptiveKNN", "AdaptiveRandomForest"
    ],
    "available_classifiers": [
      "RandomForest", "KNN", "NaiveBayes", 
      "MLP", "AdaptiveKNN", "AdaptiveRandomForest"
    ],
    "training_history": [
      {
        "timestamp": "2024-01-15T10:00:00Z",
        "duration_seconds": 487.23,
        "models_trained": 6,
        "avg_accuracy": 0.78
      }
    ],
    "model_metadata": {
      "RandomForest": {
        "performance": {"accuracy": 0.85, "f1": 0.82},
        "trained": true,
        "classifier_type": "RandomForestClassifier"
      }
    }
  }
}

# Clear all models
curl -X DELETE http://localhost:5001/api/ml/models

# Load saved models
curl -X POST http://localhost:5001/api/ml/models \
  -H "Content-Type: application/json" \
  -d '{"model_path": "models/"}'
```

#### 4. System Health and Monitoring
```bash
# Check ML system health
curl http://localhost:5001/api/ml/health

# Get detailed system status
curl http://localhost:5001/api/ml/status

# Performance benchmarking
curl -X POST http://localhost:5001/api/ml/benchmark \
  -H "Content-Type: application/json" \
  -d '{
    "num_samples": 1000,
    "iterations": 5,
    "measure_latency": true
  }'

# Response
{
  "status": "success",
  "benchmark_results": {
    "RandomForest": {
      "throughput_sessions_per_second": 1250.5,
      "average_authentication_latency_ms": 0.8,
      "total_processing_time_seconds": 0.8,
      "sessions_processed": 1000
    },
    "MLP": {
      "throughput_sessions_per_second": 2100.3,
      "average_authentication_latency_ms": 0.47,
      "total_processing_time_seconds": 0.47,
      "sessions_processed": 1000
    }
  }
}
```

### Authentication and Authorization

API Key Management:
```bash
# All ML API endpoints require authentication
# Add API key to requests:
curl -H "Authorization: Bearer your_api_key" \
     -H "Content-Type: application/json" \
     http://localhost:5001/api/ml/health

# For VM agents:
curl -H "Authorization: Bearer vm_agent_token" \
     -H "Content-Type: application/json" \
     -X POST http://localhost:5001/telemetry \
     -d '{"session_id": "session_123", ...}'

# For admin operations:
curl -H "Authorization: Bearer admin_token" \
     -H "Content-Type: application/json" \
     -X POST http://localhost:5001/api/ml/train
```

---

## üìä Monitoring & Visualization

### Available Dashboards

#### 1. Kibana Dashboards (Port 5601)
```bash
# Access Kibana
http://localhost:5601

# Default credentials
Username: elastic  
Password: trust-engine-elastic-password

# Pre-configured dashboards:
- ML Performance Metrics
- Trust Score Distribution  
- Network Flow Analysis
- System Health Monitoring
- Real-time Predictions
- Security Incident Tracking
```

Key Kibana Visualizations:
- Trust Score Heatmap: Geographic distribution of trust scores
- Model Performance Timeline: Accuracy trends over time
- Prediction Latency: Response time monitoring
- Feature Importance: Most influential network features
- Risk Level Distribution: Breakdown of security risk levels
- Session Analytics: User behavior patterns

#### 2. Wazuh Dashboard (Port 5602)
```bash
# Access Wazuh Dashboard
https://localhost:5602

# Default credentials  
Username: admin
Password: SecretPassword

# Security monitoring features:
- Threat Detection Alerts
- Vulnerability Assessment
- Compliance Monitoring
- Incident Response Tracking
- Agent Status Monitoring
- Rule Management
```

#### 3. Trust Engine Built-in Visualizations
```bash
# Generate ML performance charts
curl http://localhost:5001/api/ml/visualize/confusion_matrix
curl http://localhost:5001/api/ml/visualize/roc_curves
curl http://localhost:5001/api/ml/visualize/feature_importance
curl http://localhost:5001/api/ml/visualize/performance_comparison
curl http://localhost:5001/api/ml/visualize/trust_score_distribution

# Charts are saved to: charts/ directory
- confusion_matrices.png
- roc_curves.png  
- feature_importance.png
- classifier_comparison.png
- trust_score_distribution.png
```

### Key Metrics to Monitor

#### ML Performance Metrics:
```bash
# Model Accuracy (Target: >85%)
- Overall accuracy across all models
- Per-model accuracy comparison
- Accuracy trends over time
- False positive/negative rates

# Prediction Performance (Target: <50ms)
- Average prediction latency
- 95th percentile response time
- Throughput (predictions/second)
- Memory usage per prediction

# Training Metrics
- Training duration (Target: <15 minutes)
- Model convergence rates
- Cross-validation scores
- Feature importance stability
```

#### System Performance Metrics:
```bash
# API Performance (Target: <200ms)
- Endpoint response times
- Request throughput
- Error rates (Target: <1%)
- Concurrent user capacity

# Resource Utilization
- CPU usage (Target: <80%)
- Memory usage (Target: <80%) 
- Disk I/O
- Network bandwidth

# Service Health
- Container uptime
- Service availability (Target: 99.9%)
- Database connection health
- External service dependencies
```

#### Security Metrics:
```bash
# Trust Score Analytics
- Average trust score distribution
- High-risk session count (Monitor for spikes)
- MFA trigger rate (Expected: 10-20%)
- Access denial rate (Expected: <5%)

# Threat Detection
- Security alert volume
- Incident response time
- False alarm rate
- Threat classification accuracy
```

### Automated Monitoring Setup

Prometheus/Grafana Integration:
```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
```

Custom Monitoring Script:
```python
#!/usr/bin/env python3
# monitoring/health_monitor.py

import requests
import time
import json
import logging
from datetime import datetime

class TrustEngineMonitor:
    def __init__(self, base_url="http://localhost:5001"):
        self.base_url = base_url
        self.setup_logging()
        
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('monitoring.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def check_service_health(self):
        """Check all service endpoints"""
        services = {
            "Trust Engine API": f"{self.base_url}/",
            "ML API": f"{self.base_url}/api/ml/health", 
            "Elasticsearch": "http://localhost:9200/_cluster/health",
            "Kibana": "http://localhost:5601/api/status"
        }
        
        results = {}
        for service, url in services.items():
            try:
                response = requests.get(url, timeout=10)
                results[service] = {
                    "status": "healthy" if response.status_code == 200 else "unhealthy",
                    "response_time": response.elapsed.total_seconds(),
                    "status_code": response.status_code
                }
                self.logger.info(f"‚úÖ {service}: Healthy ({response.elapsed.total_seconds():.2f}s)")
            except Exception as e:
                results[service] = {
                    "status": "down",
                    "error": str(e)
                }
                self.logger.error(f"‚ùå {service}: Down - {str(e)}")
                
        return results
        
    def check_ml_performance(self):
        """Monitor ML model performance"""
        try:
            response = requests.get(f"{self.base_url}/api/ml/models")
            data = response.json()
            
            if data.get('status') == 'success':
                model_info = data.get('model_info', {})
                trained_models = model_info.get('trained_models', [])
                
                self.logger.info(f"üìä ML Models: {len(trained_models)} trained")
                
                # Check if retraining is needed (example: if last training > 7 days)
                last_training = model_info.get('training_history', [])
                if last_training:
                    last_date = datetime.fromisoformat(last_training[-1]['timestamp'].replace('Z', '+00:00'))
                    days_since = (datetime.now().astimezone() - last_date).days
                    
                    if days_since > 7:
                        self.logger.warning(f"‚ö†Ô∏è  Models need retraining (last trained {days_since} days ago)")
                        
                return True
                
        except Exception as e:
            self.logger.error(f"‚ùå ML Performance check failed: {str(e)}")
            return False
            
    def run_continuous_monitoring(self, interval=300):  # 5 minutes
        """Run continuous monitoring"""
        self.logger.info("üöÄ Starting Trust Engine continuous monitoring")
        
        while True:
            try:
                self.logger.info("=" * 50)
                self.logger.info(f"üîç Health Check - {datetime.now()}")
                
                # Check service health
                service_results = self.check_service_health()
                
                # Check ML performance
                ml_status = self.check_ml_performance()
                
                # Generate alerts if needed
                unhealthy_services = [
                    service for service, result in service_results.items() 
                    if result.get('status') != 'healthy'
                ]
                
                if unhealthy_services:
                    self.logger.error(f"üö® ALERT: Unhealthy services: {', '.join(unhealthy_services)}")
                    # Send notification (email, Slack, etc.)
                    
                self.logger.info(f"‚úÖ Health check complete. Next check in {interval} seconds.")
                time.sleep(interval)
                
            except KeyboardInterrupt:
                self.logger.info("üõë Monitoring stopped by user")
                break
            except Exception as e:
                self.logger.error(f"‚ùå Monitoring error: {str(e)}")
                time.sleep(interval)

if __name__ == "__main__":
    monitor = TrustEngineMonitor()
    monitor.run_continuous_monitoring()
```

---

## üîß Troubleshooting

### Common Issues & Solutions

#### 1. Docker Services Not Starting

Symptoms:
- Services fail to start
- Containers exit immediately
- Port binding errors

Diagnostic Commands:
```bash
# Check service status
docker-compose ps

# View logs for specific service
docker-compose logs trust-engine-app
docker-compose logs elasticsearch
docker-compose logs kibana
docker-compose logs wazuh-manager

# Check resource usage
docker stats

# Check port conflicts
netstat -tulpn | grep :5001
netstat -tulpn | grep :9200
```

Solutions:
```bash
# Solution 1: Restart services
docker-compose down
docker-compose up -d

# Solution 2: Rebuild containers
docker-compose down --volumes
docker-compose build --no-cache
docker-compose up -d

# Solution 3: Check disk space
df -h
# If low on space, clean Docker
docker system prune -af
docker volume prune

# Solution 4: Increase Docker memory/CPU
# Edit Docker Desktop settings:
# Memory: 8GB minimum
# CPU: 4 cores minimum
```

#### 2. ML API Not Responding

Symptoms:
- 404 errors on /api/ml/* endpoints
- Connection refused errors
- Timeouts on ML operations

Diagnostic Steps:
```bash
# Check if Flask app is running
curl http://localhost:5001/

# Check ML API health
curl http://localhost:5001/api/ml/health

# View application logs
docker-compose logs trust-engine-app | tail -50

# Check if ML components loaded
docker exec trust-engine-app python -c "
from app.ml_engine import TrustScoreMLEngine
print('ML Engine loaded successfully')
"
```

Solutions:
```bash
# Solution 1: Restart Trust Engine container
docker-compose restart trust-engine-app

# Solution 2: Check environment variables
docker exec trust-engine-app env | grep -E "FLASK|ML|ELASTICSEARCH"

# Solution 3: Verify circular import fix
docker exec trust-engine-app python -c "
import app
print('App imported successfully')
"

# Solution 4: Rebuild with latest changes
docker-compose build trust-engine-app
docker-compose up -d trust-engine-app
```

#### 3. Training Failures

Symptoms:
- Training endpoint returns 500 errors
- Training never completes
- Out of memory errors

Diagnostic Commands:
```bash
# Test training endpoint
curl -X POST http://localhost:5001/api/ml/train \
  -H "Content-Type: application/json" \
  -d '{"use_sample_data": true, "test_size": 0.2}'

# Check memory usage during training
docker stats trust-engine-app

# View detailed training logs
docker exec trust-engine-app tail -f /app/logs/training.log
```

Solutions:
```bash
# Solution 1: Increase container memory
# Edit docker-compose.yml:
services:
  trust-engine-app:
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

# Solution 2: Reduce training complexity
curl -X POST http://localhost:5001/api/ml/train \
  -H "Content-Type: application/json" \
  -d '{
    "use_sample_data": true,
    "algorithms": ["RandomForest"],
    "cross_validation": false,
    "test_size": 0.3
  }'

# Solution 3: Clear existing models
curl -X DELETE http://localhost:5001/api/ml/models

# Solution 4: Check dataset integrity
docker exec trust-engine-app python -c "
from app.utils import load_sample_cicids2017_data
df = load_sample_cicids2017_data()
print(f'Dataset loaded: {df.shape}')
"
```

#### 4. Elasticsearch Issues

Symptoms:
- Cluster health is red/yellow
- Connection timeouts
- Index creation failures

Diagnostic Commands:
```bash
# Check Elasticsearch health
curl http://localhost:9200/_cluster/health?pretty

# Check cluster nodes
curl http://localhost:9200/_cat/nodes?v

# Check indices
curl http://localhost:9200/_cat/indices?v

# View Elasticsearch logs
docker-compose logs elasticsearch | tail -50
```

Solutions:
```bash
# Solution 1: Restart Elasticsearch
docker-compose restart elasticsearch
# Wait 2-3 minutes for full startup

# Solution 2: Check disk space
df -h
# Elasticsearch needs >15% free disk space

# Solution 3: Increase memory if needed
# Edit docker-compose.yml:
elasticsearch:
  environment:
    - "ES_JAVA_OPTS=-Xms2g -Xmx4g"

# Solution 4: Reset Elasticsearch data
docker-compose down
docker volume rm trust_engine_app_elasticsearch-data
docker-compose up -d elasticsearch
```

#### 5. Authentication Problems

Symptoms:
- Okta login redirects fail
- 401 unauthorized errors
- Session timeouts

Diagnostic Steps:
```bash
# Verify Okta configuration
echo $OKTA_ISSUER
echo $OKTA_CLIENT_ID

# Test Okta connection
curl -I $OKTA_ISSUER/.well-known/openid_configuration

# Check application logs for auth errors
docker-compose logs trust-engine-app | grep -i auth
```

Solutions:
```bash
# Solution 1: Update environment variables
# Edit .env file with correct Okta settings
# Restart container: docker-compose restart trust-engine-app

# Solution 2: Check Okta application configuration
# - Verify redirect URIs in Okta admin console
# - Confirm client ID and secret are correct
# - Check application assignment in Okta

# Solution 3: Test with mock authentication (development)
# Set FLASK_ENV=development for bypass mode
```

#### 6. Performance Issues

Symptoms:
- Slow API responses (>200ms)
- High CPU/memory usage
- Prediction timeouts

Performance Analysis:
```bash
# Monitor resource usage
docker stats --no-stream

# Test API response times
time curl http://localhost:5001/api/ml/health

# Profile prediction performance
curl -X POST http://localhost:5001/api/ml/benchmark \
  -H "Content-Type: application/json" \
  -d '{"num_samples": 100, "iterations": 5}'

# Check for memory leaks
docker exec trust-engine-app python -c "
import psutil
import os
process = psutil.Process(os.getpid())
print(f'Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB')
"
```

Optimization Solutions:
```bash
# Solution 1: Optimize model parameters
# Use fewer estimators for RandomForest
# Reduce MLP hidden layer size
# Disable cross-validation for faster training

# Solution 2: Implement caching
# Cache trained models in memory
# Use Redis for session caching

# Solution 3: Horizontal scaling
# Run multiple Trust Engine instances
# Use load balancer (nginx/haproxy)

# Solution 4: Database optimization
# Add indices to frequently queried fields
# Implement connection pooling
```

### Advanced Debugging

#### Debug Mode Setup:
```bash
# Enable debug mode
export FLASK_DEBUG=1
export FLASK_ENV=development

# Run with debug logging
docker-compose logs -f trust-engine-app
```

#### Python Debugging:
```python
# Add to problematic code sections
import logging
import traceback

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

try:
    # Problematic code here
    result = some_function()
    logger.debug(f"Function result: {result}")
except Exception as e:
    logger.error(f"Error occurred: {str(e)}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    raise
```

#### Health Check Script:
```bash
#!/bin/bash
# debug/comprehensive_health_check.sh

echo "üîç Trust Engine Comprehensive Health Check"
echo "=========================================="

# Function to check service
check_service() {
    local name=$1
    local url=$2
    local expected_code=${3:-200}
    
    echo -n "Checking $name... "
    
    if response=$(curl -s -o /dev/null -w "%{http_code}" "$url" 2>/dev/null); then
        if [ "$response" -eq "$expected_code" ]; then
            echo "‚úÖ OK (HTTP $response)"
        else
            echo "‚ö†Ô∏è  Warning (HTTP $response)"
        fi
    else
        echo "‚ùå Failed (Connection error)"
    fi
}

# Check all services
check_service "Trust Engine API" "http://localhost:5001/"
check_service "ML API Health" "http://localhost:5001/api/ml/health"
check_service "Elasticsearch" "http://localhost:9200/_cluster/health"
check_service "Kibana" "http://localhost:5601/api/status"

# Check Docker containers
echo ""
echo "üì¶ Docker Container Status:"
docker-compose ps

# Check resource usage
echo ""
echo "üíª Resource Usage:"
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"

# Check disk space
echo ""
echo "üíæ Disk Usage:"
df -h | head -5

echo ""
echo "üèÅ Health check complete: $(date)"
```

#### Log Analysis Tools:
```bash
# Real-time log monitoring
docker-compose logs -f trust-engine-app | grep -i error

# Log aggregation and analysis
docker-compose logs --since=1h trust-engine-app | \
  grep -E "(ERROR|WARNING|CRITICAL)" | \
  sort | uniq -c | sort -nr

# Performance log analysis
docker-compose logs trust-engine-app | \
  grep "prediction.*ms" | \
  awk '{print $NF}' | \
  sed 's/[()]//g' | \
  sort -n | \
  tail -10
```

---

## üéØ Production Deployment Checklist

### Security Hardening

#### Authentication & Authorization:
```bash
# ‚úÖ Change all default passwords
- Elasticsearch: elastic user password
- Kibana: kibana_system user password  
- Wazuh: admin user password
- Trust Engine: Flask secret key

# ‚úÖ Configure SSL/TLS certificates
# Generate production certificates:
openssl req -x509 -newkey rsa:4096 \
  -keyout private/trust-engine-prod-key.pem \
  -out certs/trust-engine-prod-cert.pem \
  -days 365 -nodes \
  -subj "/C=US/ST=State/L=City/O=Organization/CN=yourdomain.com"

# ‚úÖ Set up proper API key management
- Generate secure API keys for VM agents
- Implement key rotation policy
- Use environment variables for secrets
- Never commit keys to version control

# ‚úÖ Configure Okta for production
- Set production redirect URIs
- Configure proper scopes and claims
- Enable MFA for admin accounts
- Set up user provisioning/deprovisioning
```

#### Network Security:
```bash
# ‚úÖ Configure firewall rules
# Allow only necessary ports:
ufw allow 22/tcp     # SSH
ufw allow 80/tcp     # HTTP redirect
ufw allow 443/tcp    # HTTPS
ufw allow 5001/tcp   # Trust Engine (internal only)
ufw deny 9200/tcp    # Elasticsearch (internal only)
ufw deny 5601/tcp    # Kibana (internal only)

# ‚úÖ Set up reverse proxy (nginx)
# /etc/nginx/sites-available/trust-engine:
server {
    listen 443 ssl http2;
    server_name yourdomain.com;
    
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    
    location / {
        proxy_pass http://localhost:5001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# ‚úÖ Enable log retention and rotation
# /etc/logrotate.d/trust-engine:
/var/log/trust-engine/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    create 644 root root
    postrotate
        docker-compose restart trust-engine-app
    endscript
}
```

#### Data Protection:
```bash
# ‚úÖ Encrypt data at rest
# Configure Elasticsearch encryption:
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.http.ssl.enabled: true

# ‚úÖ Set up database backups
# Automated backup script:
#!/bin/bash
# /usr/local/bin/backup-trust-engine.sh
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/trust-engine"

# Backup Elasticsearch data
docker exec elasticsearch \
  elasticsearch-dump --input=http://localhost:9200 \
  --output=$BACKUP_DIR/elasticsearch_$DATE.json

# Backup application data
docker exec trust-engine-app \
  tar -czf $BACKUP_DIR/app_data_$DATE.tar.gz /app/data

# Keep only last 30 days of backups
find $BACKUP_DIR -name "*.tar.gz" -mtime +30 -delete
find $BACKUP_DIR -name "*.json" -mtime +30 -delete

# Add to crontab:
# 0 2 * * * /usr/local/bin/backup-trust-engine.sh
```

### Performance Optimization

#### Resource Allocation:
```yaml
# production-docker-compose.yml
version: '3.8'

services:
  trust-engine-app:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    
  elasticsearch:
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    environment:
      - "ES_JAVA_OPTS=-Xms4g -Xmx4g"
      - cluster.name=trust-engine-prod
      - discovery.type=single-node
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
```

#### Load Balancing and Scaling:
```nginx
# /etc/nginx/conf.d/trust-engine-lb.conf
upstream trust_engine_backend {
    least_conn;
    server 127.0.0.1:5001 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:5002 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:5003 max_fails=3 fail_timeout=30s;
}

server {
    listen 443 ssl http2;
    server_name api.yourdomain.com;
    
    location /api/ml/ {
        proxy_pass http://trust_engine_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_connect_timeout 60s;
        proxy_read_timeout 300s;  # For ML training operations
    }
}
```

#### Caching Strategy:
```python
# app/cache.py
import redis
import json
from functools import wraps

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_predictions(expiration=300):  # 5 minutes
    def decorator(func):
        @wraps(func)
        def wrapper(*args, kwargs):
            # Create cache key from function arguments
            cache_key = f"prediction:{hash(str(args) + str(kwargs))}"
            
            # Try to get from cache
            cached_result = redis_client.get(cache_key)
            if cached_result:
                return json.loads(cached_result)
            
            # Execute function and cache result
            result = func(*args, kwargs)
            redis_client.setex(
                cache_key, 
                expiration, 
                json.dumps(result)
            )
            
            return result
        return wrapper
    return decorator

# Usage:
@cache_predictions(expiration=600)
def predict_trust_score(features, model_name):
    # ... prediction logic
    return prediction_result
```

### Monitoring and Alerting

#### Production Monitoring Setup:
```yaml
# monitoring/docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml

volumes:
  prometheus-data:
  grafana-data:
```

#### Alert Configuration:
```yaml
# alertmanager/alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@yourdomain.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
- name: 'web.hook'
  email_configs:
  - to: 'admin@yourdomain.com'
    subject: 'Trust Engine Alert: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
```

#### Critical Alerts Setup:
```python
# monitoring/alerting.py
import smtplib
import requests
import json
from email.mime.text import MimeText
from datetime import datetime

class TrustEngineAlerting:
    def __init__(self):
        self.alert_thresholds = {
            'high_risk_sessions': 10,  # Alert if >10 high-risk sessions/hour
            'avg_trust_score': 5.0,   # Alert if avg trust score <5.0
            'prediction_latency': 100, # Alert if prediction >100ms
            'model_accuracy': 0.80,   # Alert if accuracy <80%
            'api_error_rate': 0.05    # Alert if error rate >5%
        }
        
    def check_high_risk_sessions(self):
        """Monitor for unusual high-risk session spikes"""
        response = requests.get('http://localhost:5001/api/ml/stats/high_risk')
        data = response.json()
        
        if data.get('count_last_hour', 0) > self.alert_thresholds['high_risk_sessions']:
            self.send_alert(
                subject="High Risk Sessions Alert",
                message=f"Detected {data['count_last_hour']} high-risk sessions in the last hour"
            )
            
    def check_model_performance(self):
        """Monitor model accuracy and performance"""
        response = requests.get('http://localhost:5001/api/ml/models')
        data = response.json()
        
        for model_name, metrics in data.get('model_metadata', {}).items():
            accuracy = metrics.get('performance', {}).get('accuracy', 1.0)
            if accuracy < self.alert_thresholds['model_accuracy']:
                self.send_alert(
                    subject=f"Model Performance Alert - {model_name}",
                    message=f"Model {model_name} accuracy dropped to {accuracy:.2f}"
                )
                
    def send_alert(self, subject, message):
        """Send alert via email and Slack"""
        # Email alert
        self.send_email_alert(subject, message)
        
        # Slack alert (if configured)
        self.send_slack_alert(subject, message)
        
    def send_email_alert(self, subject, message):
        """Send email alert"""
        try:
            msg = MimeText(message)
            msg['Subject'] = f"[Trust Engine] {subject}"
            msg['From'] = 'alerts@yourdomain.com'
            msg['To'] = 'admin@yourdomain.com'
            
            with smtplib.SMTP('localhost', 587) as server:
                server.send_message(msg)
        except Exception as e:
            print(f"Failed to send email alert: {e}")
            
    def send_slack_alert(self, subject, message):
        """Send Slack alert"""
        webhook_url = "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
        payload = {
            "text": f"üö® {subject}",
            "attachments": [
                {
                    "color": "danger",
                    "fields": [
                        {
                            "title": "Details",
                            "value": message,
                            "short": False
                        }
                    ]
                }
            ]
        }
        
        try:
            requests.post(webhook_url, json=payload)
        except Exception as e:
            print(f"Failed to send Slack alert: {e}")
```

### Maintenance and Operations

#### Backup and Recovery:
```bash
#!/bin/bash
# scripts/backup-restore.sh

BACKUP_DIR="/backup/trust-engine"
DATE=$(date +%Y%m%d_%H%M%S)

backup_elasticsearch() {
    echo "üîÑ Backing up Elasticsearch data..."
    docker exec elasticsearch \
        curl -X PUT "localhost:9200/_snapshot/backup_repo" \
        -H 'Content-Type: application/json' \
        -d '{
            "type": "fs",
            "settings": {
                "location": "/backup"
            }
        }'
    
    docker exec elasticsearch \
        curl -X PUT "localhost:9200/_snapshot/backup_repo/snapshot_$DATE"
}

backup_models() {
    echo "üîÑ Backing up ML models..."
    docker exec trust-engine-app \
        tar -czf /backup/models_$DATE.tar.gz /app/models/
}

backup_configuration() {
    echo "üîÑ Backing up configuration..."
    tar -czf $BACKUP_DIR/config_$DATE.tar.gz \
        docker-compose.yml \
        .env \
        docker/ \
        kibana/ \
        monitoring/
}

restore_from_backup() {
    local backup_date=$1
    echo "üîÑ Restoring from backup: $backup_date"
    
    # Restore Elasticsearch
    docker exec elasticsearch \
        curl -X POST "localhost:9200/_snapshot/backup_repo/snapshot_$backup_date/_restore"
    
    # Restore models
    docker exec trust-engine-app \
        tar -xzf /backup/models_$backup_date.tar.gz -C /
    
    # Restart services
    docker-compose restart
}

# Main backup function
main() {
    case "$1" in
        backup)
            mkdir -p $BACKUP_DIR
            backup_elasticsearch
            backup_models
            backup_configuration
            echo "‚úÖ Backup completed: $DATE"
            ;;
        restore)
            if [ -z "$2" ]; then
                echo "Usage: $0 restore <backup_date>"
                exit 1
            fi
            restore_from_backup $2
            ;;
        *)
            echo "Usage: $0 {backup|restore} [backup_date]"
            exit 1
            ;;
    esac
}

main "$@"
```

#### Update and Maintenance Procedures:
```bash
#!/bin/bash
# scripts/maintenance.sh

update_system() {
    echo "üîÑ Updating Trust Engine system..."
    
    # 1. Backup current state
    ./backup-restore.sh backup
    
    # 2. Pull latest images
    docker-compose pull
    
    # 3. Update application code
    git pull origin main
    
    # 4. Rebuild containers
    docker-compose build --no-cache
    
    # 5. Rolling update
    docker-compose up -d --force-recreate
    
    # 6. Verify health
    sleep 30
    ./health_check.sh
    
    echo "‚úÖ System update completed"
}

retrain_models() {
    echo "üß† Retraining ML models..."
    
    # Backup current models
    docker exec trust-engine-app \
        cp -r /app/models /app/models_backup_$(date +%Y%m%d)
    
    # Retrain with latest data
    curl -X POST http://localhost:5001/api/ml/train \
        -H "Content-Type: application/json" \
        -d '{
            "use_sample_data": false,
            "data_source": "multiple_files",
            "cross_validation": true,
            "save_models": true
        }'
    
    echo "‚úÖ Model retraining completed"
}

cleanup_old_data() {
    echo "üßπ Cleaning up old data..."
    
    # Remove old logs
    find /var/log/trust-engine -name "*.log" -mtime +30 -delete
    
    # Remove old backups
    find /backup/trust-engine -name "*.tar.gz" -mtime +30 -delete
    
    # Clean Docker system
    docker system prune -f
    
    echo "‚úÖ Cleanup completed"
}

case "$1" in
    update)
        update_system
        ;;
    retrain)
        retrain_models
        ;;
    cleanup)
        cleanup_old_data
        ;;
    *)
        echo "Usage: $0 {update|retrain|cleanup}"
        exit 1
        ;;
esac
```

### Security Best Practices

#### Regular Security Tasks:
```bash
# Security checklist (run weekly)
#!/bin/bash
# scripts/security_audit.sh

echo "üîí Trust Engine Security Audit"
echo "=============================="

# 1. Check for security updates
echo "üì¶ Checking for security updates..."
docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.CreatedAt}}" | head -10

# 2. Audit user access
echo "üë• Auditing user access..."
curl -s http://localhost:5001/api/admin/users | jq '.active_users | length'

# 3. Check SSL certificate expiry
echo "üîê Checking SSL certificates..."
openssl x509 -in docker/ssl/certs/trust-engine-cert.pem -noout -dates

# 4. Review high-risk sessions
echo "‚ö†Ô∏è  Reviewing high-risk sessions..."
curl -s http://localhost:5001/api/ml/stats/high_risk | jq '.count_last_week'

# 5. Check for failed login attempts
echo "üö´ Checking failed login attempts..."
docker logs trust-engine-app 2>&1 | grep -i "failed login" | tail -10

# 6. Verify firewall rules
echo "üî• Verifying firewall status..."
ufw status | grep -E "(5001|9200|5601)"

echo "‚úÖ Security audit completed"
```

#### Incident Response Plan:
```markdown
## üö® Incident Response Procedures

### High-Risk Session Detection
1. Immediate Actions:
   - Block suspicious session: `curl -X POST /api/admin/block_session`
   - Review session details in Kibana
   - Check for related suspicious activity

2. Investigation:
   - Analyze network flow patterns
   - Check Wazuh alerts for related events
   - Review user access logs

3. Remediation:
   - Update ML models if new attack pattern
   - Adjust trust score thresholds
   - Implement additional monitoring

### System Compromise
1. Containment:
   - Isolate affected components
   - Preserve evidence: `./backup-restore.sh backup`
   - Block malicious IPs at firewall

2. Eradication:
   - Update all systems and containers
   - Reset all API keys and passwords
   - Review and update security policies

3. Recovery:
   - Restore from clean backup if needed
   - Gradually restore services
   - Monitor for recurring issues

### Data Breach Response
1. Assessment:
   - Determine scope of data accessed
   - Identify affected users/systems
   - Document timeline of events

2. Notification:
   - Notify affected users within 24 hours
   - Report to regulatory authorities if required
   - Update incident response documentation

3. Prevention:
   - Implement additional encryption
   - Enhanced access controls
   - Improved monitoring and alerting
```

---

## üéì Training and Documentation

### User Training Materials

#### End User Quick Start Guide:
```markdown
# Trust Engine - User Quick Start

## What is Trust Engine?
Trust Engine provides adaptive, AI-powered authentication that adjusts security based on risk assessment.

## How It Works
1. Login normally through your company's Okta portal
2. Trust Engine analyzes your session in real-time
3. Access is granted based on calculated trust score:
   - High Trust (8-10): Direct access
   - Medium Trust (5-7): MFA required
   - Low Trust (1-4): Access denied

## What Affects Your Trust Score?
- Network location and patterns
- Device characteristics
- Time and frequency of access
- Behavioral patterns

## Troubleshooting
- Unexpected MFA prompt: Normal for new locations/devices
- Access denied: Contact IT support
- Slow login: System is analyzing - please wait

## Support
- Email: it-support@company.com
- Phone: (555) 123-4567
- Help Desk: https://helpdesk.company.com
```

#### Administrator Training:
```markdown
# Trust Engine - Administrator Guide

## Daily Operations
1. Morning Check (5 minutes):
   - Review overnight alerts in Kibana
   - Check system health: `curl localhost:5001/api/ml/health`
   - Verify model performance metrics

2. Weekly Tasks (30 minutes):
   - Run security audit: `./scripts/security_audit.sh`
   - Review and retrain models if needed
   - Update threat intelligence feeds

3. Monthly Tasks (2 hours):
   - Full system backup and recovery test
   - Performance optimization review
   - User access audit and cleanup

## Emergency Procedures
- System Down: Follow incident response plan
- Security Alert: Block ‚Üí Investigate ‚Üí Remediate
- Performance Issues: Check resources ‚Üí Scale if needed

## Key Metrics to Monitor
- Trust score distribution
- Model accuracy (target: >85%)
- API response time (target: <200ms)
- Error rates (target: <1%)
```

### Developer Documentation

#### API Integration Examples:
```python
# Python SDK Usage Examples
from trust_engine_sdk import TrustEngineClient

# Initialize client
client = TrustEngineClient(
    base_url="https://trust-api.company.com",
    api_key="your_api_key"
)

# Example 1: Check trust score for user session
trust_data = client.get_trust_score(
    session_id="session_12345",
    user_id="user@company.com"
)

if trust_data['trust_score'] >= 7:
    grant_access()
elif trust_data['mfa_required']:
    require_mfa()
else:
    deny_access()

# Example 2: Submit telemetry data
telemetry = {
    "session_id": "session_12345",
    "vm_id": "vm_001",
    "network_flows": {...}  # CICIDS2017 features
}

result = client.submit_telemetry(telemetry)
print(f"Trust score: {result['trust_score']}")

# Example 3: Batch prediction for multiple sessions
sessions = [
    {"session_id": "session_1", "features": {...}},
    {"session_id": "session_2", "features": {...}}
]

predictions = client.predict_batch(sessions)
for prediction in predictions:
    print(f"Session {prediction['session_id']}: {prediction['trust_score']}")
```

#### Custom Model Development:
```python
# Custom ML Model Integration
from trust_engine.ml import BaseClassifier
import joblib

class CustomTrustClassifier(BaseClassifier):
    def __init__(self, params):
        super().__init__()
        self.model = None
        self.params = params
        
    def train(self, X, y):
        """Train the custom model"""
        from sklearn.ensemble import GradientBoostingClassifier
        
        self.model = GradientBoostingClassifier(self.params)
        self.model.fit(X, y)
        
        return self
        
    def predict(self, X):
        """Make predictions"""
        if self.model is None:
            raise ValueError("Model not trained")
            
        # Return trust scores (1-10 scale)
        raw_predictions = self.model.predict_proba(X)
        trust_scores = self._convert_to_trust_scores(raw_predictions)
        
        return trust_scores
        
    def _convert_to_trust_scores(self, probabilities):
        """Convert model probabilities to trust scores"""
        # Custom logic to map probabilities to 1-10 trust scale
        benign_prob = probabilities[:, 1]  # Assuming benign is class 1
        trust_scores = 1 + (benign_prob * 9)  # Scale to 1-10
        
        return trust_scores.astype(int)
        
    def save(self, filepath):
        """Save trained model"""
        joblib.dump(self.model, filepath)
        
    def load(self, filepath):
        """Load trained model"""
        self.model = joblib.load(filepath)
        return self

# Register custom model with Trust Engine
from trust_engine.ml import register_custom_classifier

register_custom_classifier(
    name="CustomGradientBoosting",
    classifier_class=CustomTrustClassifier,
    default_params={
        'n_estimators': 100,
        'learning_rate': 0.1,
        'max_depth': 6
    }
)
```

---

## üìà Performance Benchmarking

### Benchmark Results

#### System Performance Metrics:
```
üöÄ Trust Engine Performance Benchmark
=====================================

Hardware Configuration:
- CPU: 4 cores @ 2.5GHz
- RAM: 16GB DDR4
- Storage: SSD 500GB
- Network: 1Gbps

ML Model Performance:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Model               ‚îÇ Accuracy ‚îÇ Latency (ms)‚îÇ Throughput   ‚îÇ Memory (MB) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ RandomForest        ‚îÇ 85.2%    ‚îÇ 12.3        ‚îÇ 2,150/sec    ‚îÇ 145         ‚îÇ
‚îÇ KNN                 ‚îÇ 79.1%    ‚îÇ 8.7         ‚îÇ 3,200/sec    ‚îÇ 89          ‚îÇ
‚îÇ NaiveBayes          ‚îÇ 77.5%    ‚îÇ 3.2         ‚îÇ 8,500/sec    ‚îÇ 45          ‚îÇ
‚îÇ MLP                 ‚îÇ 82.8%    ‚îÇ 15.6        ‚îÇ 1,800/sec    ‚îÇ 178         ‚îÇ
‚îÇ AdaptiveKNN         ‚îÇ 81.4%    ‚îÇ 11.2        ‚îÇ 2,400/sec    ‚îÇ 112         ‚îÇ
‚îÇ AdaptiveRandomForest‚îÇ 86.1%    ‚îÇ 18.9        ‚îÇ 1,650/sec    ‚îÇ 198         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

API Performance:
- Health Check: 2.1ms avg
- Single Prediction: 18.5ms avg  
- Batch Prediction (100): 156ms avg
- Model Training: 8.2 minutes avg
- Model Evaluation: 45 seconds avg

System Capacity:
- Concurrent Users: 10,000+
- Daily Predictions: 1M+
- Storage Growth: ~500MB/day
- Uptime: 99.95%
```

### Load Testing Scripts:
```python
# load_testing/stress_test.py
import asyncio
import aiohttp
import time
import statistics
from concurrent.futures import ThreadPoolExecutor

class TrustEngineLoadTest:
    def __init__(self, base_url="http://localhost:5001"):
        self.base_url = base_url
        self.results = []
        
    async def single_prediction_test(self, session, features):
        """Test single prediction endpoint"""
        start_time = time.time()
        
        try:
            async with session.post(
                f"{self.base_url}/api/ml/predict",
                json={"features": features, "classifier": "RandomForest"},
                headers={"Content-Type": "application/json"}
            ) as response:
                result = await response.json()
                end_time = time.time()
                
                return {
                    "success": response.status == 200,
                    "latency": (end_time - start_time) * 1000,
                    "trust_score": result.get("trust_score", 0)
                }
        except Exception as e:
            end_time = time.time()
            return {
                "success": False,
                "latency": (end_time - start_time) * 1000,
                "error": str(e)
            }
    
    async def run_concurrent_test(self, num_concurrent=100, num_requests=1000):
        """Run concurrent prediction tests"""
        print(f"üîÑ Starting load test: {num_concurrent} concurrent, {num_requests} total requests")
        
        # Sample features for testing
        sample_features = {
            "Flow Duration": 0.123,
            "Total Fwd Packets": 45,
            "Total Backward Packets": 23,
            "Flow Bytes/s": 1000000
        }
        
        async with aiohttp.ClientSession() as session:
            # Create semaphore to limit concurrent requests
            semaphore = asyncio.Semaphore(num_concurrent)
            
            async def limited_request():
                async with semaphore:
                    return await self.single_prediction_test(session, sample_features)
            
            # Run all requests
            start_time = time.time()
            tasks = [limited_request() for _ in range(num_requests)]
            results = await asyncio.gather(*tasks)
            end_time = time.time()
            
            # Analyze results
            successful_requests = [r for r in results if r["success"]]
            failed_requests = [r for r in results if not r["success"]]
            
            if successful_requests:
                latencies = [r["latency"] for r in successful_requests]
                
                print("\nüìä Load Test Results:")
                print(f"Total Requests: {num_requests}")
                print(f"Successful: {len(successful_requests)}")
                print(f"Failed: {len(failed_requests)}")
                print(f"Success Rate: {len(successful_requests)/num_requests*100:.1f}%")
                print(f"Total Time: {end_time-start_time:.2f}s")
                print(f"Requests/sec: {num_requests/(end_time-start_time):.1f}")
                print(f"Avg Latency: {statistics.mean(latencies):.1f}ms")
                print(f"95th Percentile: {statistics.quantiles(latencies, n=20)[18]:.1f}ms")
                print(f"99th Percentile: {statistics.quantiles(latencies, n=100)[98]:.1f}ms")
            
            return results

if __name__ == "__main__":
    load_tester = TrustEngineLoadTest()
    
    # Run different load scenarios
    scenarios = [
        (10, 100),    # Light load
        (50, 500),    # Medium load  
        (100, 1000),  # Heavy load
        (200, 2000),  # Stress test
    ]
    
    for concurrent, total in scenarios:
        print(f"\n{'='*60}")
        print(f"Scenario: {concurrent} concurrent, {total} total")
        asyncio.run(load_tester.run_concurrent_test(concurrent, total))
        time.sleep(10)  # Cool down between tests
```

---

## üéØ Conclusion

This comprehensive guide covers all aspects of the Trust Engine application, from basic setup to advanced production deployment. The system provides:

### Key Benefits:
- üîí Enhanced Security: AI-powered adaptive authentication
- ‚ö° High Performance: Sub-20ms prediction latency  
- üìä Full Observability: Complete monitoring and visualization
- üîß Production Ready: Docker-based, scalable architecture
- üéØ Thesis Ready: Research-grade ML pipeline with comprehensive evaluation

### Next Steps:
1. Complete Setup: Follow the installation and configuration steps
2. Integrate Real Data: Replace sample data with your CICIDS2017 RFE dataset
3. Customize Models: Tune hyperparameters and add custom classifiers
4. Deploy to Production: Follow the production deployment checklist
5. Monitor and Optimize: Use the monitoring tools to optimize performance

### Support and Resources:
- Documentation: This comprehensive guide
- API Reference: Available at `/api/ml/swagger` when running
- Monitoring: Kibana dashboards at port 5601
- Security: Wazuh dashboards at port 5602
- Health Checks: Automated monitoring scripts provided

The Trust Engine represents a complete, production-ready implementation of adaptive authentication using machine learning, perfectly suited for cybersecurity research and real-world deployment. üöÄ

---

Document Version: 1.0  
Last Updated: January 2024  
Total Pages: ~50  
Estimated Reading Time: 2-3 hours